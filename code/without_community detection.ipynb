{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import dgl\n",
    "import dgl.function as fn\n",
    "\n",
    "gcn_msg = fn.copy_src(src='h', out='m')\n",
    "gcn_reduce = fn.sum(msg='m', out='h')\n",
    "\n",
    "device = torch.device('cuda')\n",
    "\n",
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "def compute_metric(y_true, y_pred, name):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse= np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mape = mean_absolute_percentage_error(y_true[np.where(y_true > 10)[0]], y_pred[np.where(y_true > 10)[0]])\n",
    "    print(\"mae \" + name, mae)    \n",
    "    print(\"rmse \" + name, rmse)\n",
    "    print(\"mape(>10) \" + name, mape)  \n",
    "    return rmse\n",
    "\n",
    "def build_graph(src, dst, nb_nodes, device):\n",
    "    g = dgl.DGLGraph()\n",
    "    g.add_nodes(nb_nodes)\n",
    "    g.add_edges(src, dst)\n",
    "    return g.to(device)\n",
    "\n",
    "def create_batches(node_features_batch, batch_size, src, dst, nb_nodes, device):\n",
    "    my_graphs = []\n",
    "    for i in range(batch_size):\n",
    "        temp_g = build_graph(src, dst, nb_nodes, device)\n",
    "        temp_g.ndata['h'] = torch.from_numpy(node_features_batch[:,i,:]).to(device)\n",
    "        my_graphs.append(temp_g)\n",
    "    return dgl.batch(my_graphs)\n",
    "    \n",
    "\n",
    "class NodeApplyModule(nn.Module):\n",
    "    def __init__(self, in_feats, out_feats, activation):\n",
    "        super(NodeApplyModule, self).__init__()\n",
    "        self.linear = nn.Linear(in_feats, out_feats)\n",
    "        self.activation = activation\n",
    "        \n",
    "    def forward(self, node):\n",
    "        h = self.linear(node.data['h'])\n",
    "        h = self.activation(h)\n",
    "        return {'h' : h}\n",
    "    \n",
    "\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, in_feats, out_feats, activation):\n",
    "        super(GCN, self).__init__()\n",
    "        self.apply_mod = NodeApplyModule(in_feats, out_feats, activation)\n",
    "        \n",
    "    def forward(self, g, feature):\n",
    "        g.ndata['h'] = feature\n",
    "        g.update_all(gcn_msg, gcn_reduce)\n",
    "        g.apply_nodes(func=self.apply_mod)\n",
    "        return g.ndata.pop('h')\n",
    "\n",
    "class EarlyStopping:\n",
    "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
    "    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt', trace_func=print):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): How long to wait after last time validation loss improved.\n",
    "                            Default: 7\n",
    "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
    "                            Default: False\n",
    "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
    "                            Default: 0\n",
    "            path (str): Path for the checkpoint to be saved to.\n",
    "                            Default: 'checkpoint.pt'\n",
    "            trace_func (function): trace print function.\n",
    "                            Default: print            \n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "        self.trace_func = trace_func\n",
    "    def __call__(self, val_loss, model):\n",
    "\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        '''Saves model when validation loss decrease.'''\n",
    "        if self.verbose:\n",
    "            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        torch.save(model.state_dict(), self.path)\n",
    "        self.val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "class TGCN(nn.Module):\n",
    "    def __init__(self, in_dim, hidden_dim, batch_size, community_detail, device, nb_neurons_gru=20, nb_neurons_dense=10):\n",
    "        super().__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.device=device\n",
    "        self.community_detail = community_detail\n",
    "        self.nb_nodes = sum([len(_) for _ in community_detail])\n",
    "        self.grus = nn.ModuleList([nn.GRU(1, 20, 2, batch_first=True) for _ in range(self.nb_nodes)])\n",
    "\n",
    "        self.gcnlayers1 = nn.ModuleList([\n",
    "            GCN(in_dim, 32, F.relu),\n",
    "            GCN(32, hidden_dim, F.relu)\n",
    "        ])\n",
    "        \n",
    "        self.gcnlayers2 = nn.ModuleList([\n",
    "            GCN(in_dim, 32, F.relu),\n",
    "            GCN(32, hidden_dim, F.relu)\n",
    "        ])\n",
    "\n",
    "        self.fc1 = nn.Linear(40, 1)\n",
    "        \n",
    "    def forward(self, g, g2):\n",
    "        h = g.ndata['h']        \n",
    "        h = h.unsqueeze(dim=2)\n",
    "\n",
    "        gru_outputs = [gru(h[range(i, i+self.nb_nodes*self.batch_size, self.nb_nodes),:])[0][:,-1,:]\n",
    "             for i, gru in enumerate(self.grus)]\n",
    "        \n",
    "        h = torch.zeros((self.nb_nodes*self.batch_size, 20)).to(self.device)\n",
    "\n",
    "        for i in range(len(gru_outputs)):\n",
    "            h[range(i, i+self.nb_nodes*self.batch_size, self.nb_nodes),:] = gru_outputs[i]\n",
    "\n",
    "        h2 = h.clone().detach()\n",
    "        \n",
    "        for conv in self.gcnlayers1:\n",
    "            h = conv(g, h)\n",
    "        g.ndata['h'] = h\n",
    "\n",
    "        for conv in self.gcnlayers2:\n",
    "            h2 = conv(g2, h2)\n",
    "        g2.ndata['h2'] = h2\n",
    "        \n",
    "        h3 = torch.cat([h, h2], dim=1)  # (nb_nodes * batch_size, 40)\n",
    "        h3 = torch.cat([h3[i*self.nb_nodes : (i+1)*self.nb_nodes].unsqueeze(0) for i in range(self.batch_size)], dim=0) #[bs, nb_nodes, 40] \n",
    "        X = self.fc1(h3)\n",
    "        return X.squeeze(-1).T # [nb_nodes, bs]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "class SimpleGCN(nn.Module):\n",
    "    def __init__(self, in_dim, hidden_dim, batch_size, community_detail, device, nb_neurons_gru=20, nb_neurons_dense=10):\n",
    "        super().__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.device=device\n",
    "        self.community_detail = community_detail\n",
    "        self.nb_nodes = sum([len(_) for _ in community_detail])\n",
    "        \n",
    "        self.gcnlayers1 = nn.ModuleList([\n",
    "            GCN(in_dim, 32, F.relu),\n",
    "            GCN(32, hidden_dim, F.relu)\n",
    "        ])\n",
    "        \n",
    "        self.gcnlayers2 = nn.ModuleList([\n",
    "            GCN(in_dim, 32, F.relu),\n",
    "            GCN(32, hidden_dim, F.relu)\n",
    "        ])\n",
    "\n",
    "        self.fc1 = nn.Linear(40, 1)\n",
    "        \n",
    "    def forward(self, g, g2):\n",
    "        h = g.ndata['h']        \n",
    "\n",
    "        h2 = h.clone().detach()\n",
    "        \n",
    "        for conv in self.gcnlayers1:\n",
    "            h = conv(g, h)\n",
    "        g.ndata['h'] = h\n",
    "\n",
    "        for conv in self.gcnlayers2:\n",
    "            h2 = conv(g2, h2)\n",
    "        g2.ndata['h2'] = h2\n",
    "        \n",
    "        h3 = torch.cat([h, h2], dim=1)  # (nb_nodes * batch_size, 40)\n",
    "        h3 = torch.cat([h3[i*self.nb_nodes : (i+1)*self.nb_nodes].unsqueeze(0) for i in range(self.batch_size)], dim=0) #[bs, nb_nodes, 40] \n",
    "        X = self.fc1(h3)\n",
    "        return X.squeeze(-1).T # [nb_nodes, bs]\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "class SimpleGCN11(nn.Module):\n",
    "    def __init__(self, in_dim, hidden_dim, batch_size, nb_nodes, device, nb_neurons_gru=20, nb_neurons_dense=10):\n",
    "        super().__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.device=device\n",
    "        self.nb_nodes = nb_nodes\n",
    "        \n",
    "        self.gcnlayers1 = nn.ModuleList([\n",
    "            GCN(in_dim, 32, F.relu),\n",
    "            GCN(32, hidden_dim, F.relu)\n",
    "        ])\n",
    "        \n",
    "        self.gcnlayers2 = nn.ModuleList([\n",
    "            GCN(in_dim, 32, F.relu),\n",
    "            GCN(32, hidden_dim, F.relu)\n",
    "        ])\n",
    "\n",
    "        self.fcs = nn.ModuleList([nn.Linear(40, 1) for _ in range(nb_nodes)])\n",
    "        \n",
    "    def forward(self, g, g2):\n",
    "        h = g.ndata['h']        \n",
    "\n",
    "        h2 = h.clone().detach()\n",
    "        \n",
    "        for conv in self.gcnlayers1:\n",
    "            h = conv(g, h)\n",
    "        g.ndata['h'] = h\n",
    "\n",
    "        for conv in self.gcnlayers2:\n",
    "            h2 = conv(g2, h2)\n",
    "        g2.ndata['h2'] = h2\n",
    "        \n",
    "        h3 = torch.cat([h, h2], dim=1)  # (nb_nodes * batch_size, 40)\n",
    "        h3 = h3.view(-1, self.nb_nodes, 40)\n",
    "        X = [self.fcs[i](h3[:,i,:]) for i in range(self.nb_nodes)]\n",
    "        X = torch.cat(X, dim=1).T\n",
    "        \n",
    "        return X # [nb_nodes, bs]\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def train(net, X_train, X_val, y_train, y_val, saved_path, nb_nodes, community_detail, high_similar_poi, edges, batch_size = 72, \n",
    "          learning_rate=0.001, epochs=100, device=device):\n",
    "    \n",
    "    nb_train, nb_val = y_train.shape[1], y_val.shape[1]\n",
    "    \n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
    "    \n",
    "    nb_nodes = sum([len(_) for _ in community_detail])\n",
    "    \n",
    "    early_stopping = EarlyStopping(patience=7, verbose=False, path=saved_path)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        loss_all = []\n",
    "        net.train()\n",
    "        for i in range(nb_train//batch_size):\n",
    "            batched_graph1 = create_batches(X_train[:,i*batch_size:(i+1)*batch_size,:], batch_size, edges[:,0], edges[:,1], nb_nodes, device)\n",
    "            batched_graph2 = create_batches(X_train[:,i*batch_size:(i+1)*batch_size,:], batch_size, high_similar_poi['i'], high_similar_poi['j'], nb_nodes, device)\n",
    "            logits_train = net(batched_graph1, batched_graph2) # [nb_node, bs]\n",
    "            y_train_temp = torch.from_numpy(y_train[:,i*batch_size:(i+1)*batch_size]).to(device)\n",
    "            loss = F.mse_loss(logits_train, y_train_temp)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        net.eval()\n",
    "        pred_val = []\n",
    "        with torch.no_grad():\n",
    "            for i in range(nb_val//batch_size):\n",
    "                batched_graph1 = create_batches(X_val[:,i*batch_size:(i+1)*batch_size,:], batch_size, edges[:,0], edges[:,1], nb_nodes, device)\n",
    "                batched_graph2 = create_batches(X_val[:,i*batch_size:(i+1)*batch_size,:], batch_size, high_similar_poi['i'], high_similar_poi['j'], nb_nodes, device)\n",
    "                logits_val = net(batched_graph1, batched_graph2) # [nb_node, bs]\n",
    "                pred_val.append(logits_val)\n",
    "            \n",
    "            pred = torch.cat(pred_val, dim=1)\n",
    "            rmse_current = compute_metric(y_val.flatten(), pred.cpu().numpy().flatten(), str(epoch))\n",
    "            print()\n",
    "        \n",
    "        early_stopping(rmse_current, net)\n",
    "\n",
    "        if early_stopping.early_stop:\n",
    "            print('Early stopping')\n",
    "            break\n",
    "\n",
    "    net.load_state_dict(torch.load(saved_path))\n",
    "    return net\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def test(model, X_test, y_test, batch_size, edges, high_sim, nb_nodes, device):\n",
    "    pred_test = []\n",
    "    nb_test = X_test.shape[1]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i in range(nb_test//batch_size):\n",
    "            batched_graph1 = create_batches(X_test[:,i*batch_size:(i+1)*batch_size,:], batch_size, edges[:,0], edges[:,1], nb_nodes, device)\n",
    "            batched_graph2 = create_batches(X_test[:,i*batch_size:(i+1)*batch_size,:], batch_size, high_sim['i'], high_sim['j'], nb_nodes, device)\n",
    "            logits_test = model(batched_graph1, batched_graph2) # [nb_node, bs]\n",
    "            pred_test.append(logits_test)\n",
    "\n",
    "        pred = torch.cat(pred_test, dim=1)\n",
    "        rmse_current = compute_metric(y_test.flatten(), pred.cpu().numpy().flatten(), 'test')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# TGCN-SZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 1, 2, 3, 4, 6, 9, 63, 69, 77], [5, 7, 8, 10, 22, 25, 45, 46, 47, 48, 49, 50, 51, 58, 66, 71, 81], [11, 21, 24, 29, 30, 35, 37, 39, 40, 41, 42, 43, 53, 92, 96], [12, 13, 15, 16, 23, 34, 36, 54, 55, 72, 78, 79, 97], [14, 17, 18, 19, 20, 38, 44, 84, 85, 86, 87, 88, 89, 90, 91, 93, 94, 95, 98, 100], [26, 27, 28, 31, 32, 33], [52, 56, 57, 59, 60, 61, 62, 64, 65], [67, 68, 70, 73, 74, 75, 76, 80, 82, 83, 99]]\n",
      "(654, 2)\n",
      "(101, 3672, 24) (101, 3672)\n"
     ]
    }
   ],
   "source": [
    "X_train_sz = np.load('./data/taxi_sz/X_train20.npy').astype('float32')\n",
    "X_val_sz = np.load('./data/taxi_sz/X_val20.npy').astype('float32')\n",
    "X_test_sz = np.load('./data/taxi_sz/X_test20.npy').astype('float32')\n",
    "y_train_sz = np.load('./data/taxi_sz/y_train20.npy').astype('float32')\n",
    "y_val_sz = np.load('./data/taxi_sz/y_val20.npy').astype('float32')\n",
    "y_test_sz = np.load('./data/taxi_sz/y_test20.npy').astype('float32')\n",
    "\n",
    "sz_8community = np.load('./data/taxi_sz/sz_8community.npy', allow_pickle=True).tolist()\n",
    "print(sz_8community)\n",
    "\n",
    "edges_in_sz = np.load('./data/taxi_sz/edges_in_sz.npy')\n",
    "print(edges_in_sz.shape)\n",
    "\n",
    "high_similar_poi_sz = pd.read_csv('./data/taxi_sz/high_similar_poi.csv')\n",
    "\n",
    "print(X_train_sz.shape, y_train_sz.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae test 10.17994\n",
      "rmse test 15.334211\n",
      "mape(>10) test 32.654547691345215\n"
     ]
    }
   ],
   "source": [
    "test(model_sz, X_test_sz, y_test_sz, 72, edges_in_sz, high_similar_poi_sz, 101, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "Collapsed": "false",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time cost:  1.055283784866333\n"
     ]
    }
   ],
   "source": [
    "nb_test = X_test_sz.shape[1]\n",
    "\n",
    "model = TGCN(20, 20, nb_test, sz_8community, device).to(device)\n",
    "model.load_state_dict(torch.load(\"./saved/tgcn_sz.pt\"))\n",
    "\n",
    "t0 = time.time()\n",
    "with torch.no_grad():\n",
    "    batched_graph1 = create_batches(X_test_sz, nb_test, edges_in_sz[:,0], edges_in_sz[:,1], 101, device)\n",
    "    batched_graph2 = create_batches(X_test_sz, nb_test, high_similar_poi_sz['i'], high_similar_poi_sz['j'], 101, device)\n",
    "    logits_test = model(batched_graph1, batched_graph2) # [nb_node, bs]\n",
    "    print('time cost: ', time.time() - t0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# TGCN-NY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(63, 8856, 24) (63, 8856)\n"
     ]
    }
   ],
   "source": [
    "X_train_ny = np.load('./data/taxi_ny/X_train20.npy')\n",
    "y_train_ny = np.load('./data/taxi_ny/y_train20.npy')\n",
    "X_val_ny = np.load('./data/taxi_ny/X_val20.npy')\n",
    "y_val_ny = np.load('./data/taxi_ny/y_val20.npy')\n",
    "X_test_ny = np.load('./data/taxi_ny/X_test20.npy')\n",
    "y_test_ny = np.load('./data/taxi_ny/y_test20.npy')\n",
    "\n",
    "ny_6community = [[0, 5, 7, 10, 11, 12, 13, 32, 33, 49, 54], [1, 2, 4, 6, 21, 22, 24, 25, 43, 48, 56, 57, 59, 60, 61, 62],\n",
    "    [3, 8, 9, 15, 16, 28, 29, 30, 34, 55],  [14, 17, 31, 36, 37, 38, 39, 41, 46, 47, 50, 52, 53], [18, 26, 42, 45, 51], \n",
    "    [19, 20, 23, 27, 35, 40, 44, 58]]\n",
    "\n",
    "edges_in_ny = np.load('./data/taxi_ny/edges_manhattan.npy')\n",
    "ny_high_similar_poi = pd.read_csv('./data/taxi_ny/high_similar_poi.csv')\n",
    "\n",
    "print(X_train_ny.shape, y_train_ny.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "Collapsed": "false",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae 0 12.546094\n",
      "rmse 0 21.178024\n",
      "mape(>10) 0 35.97038388252258\n",
      "\n",
      "mae 1 9.140538\n",
      "rmse 1 14.032609\n",
      "mape(>10) 1 29.422244429588318\n",
      "\n",
      "mae 2 8.970854\n",
      "rmse 2 13.795502\n",
      "mape(>10) 2 31.849405169487\n",
      "\n",
      "mae 3 7.5466223\n",
      "rmse 3 12.077554\n",
      "mape(>10) 3 28.25866937637329\n",
      "\n",
      "mae 4 6.604911\n",
      "rmse 4 11.034801\n",
      "mape(>10) 4 25.520598888397217\n",
      "\n",
      "mae 5 7.3309913\n",
      "rmse 5 11.769248\n",
      "mape(>10) 5 27.420124411582947\n",
      "\n",
      "EarlyStopping counter: 1 out of 7\n",
      "mae 6 6.3626366\n",
      "rmse 6 11.05088\n",
      "mape(>10) 6 24.42053109407425\n",
      "\n",
      "EarlyStopping counter: 2 out of 7\n",
      "mae 7 6.253881\n",
      "rmse 7 10.676598\n",
      "mape(>10) 7 25.13779103755951\n",
      "\n",
      "mae 8 5.9095383\n",
      "rmse 8 10.453227\n",
      "mape(>10) 8 24.286293983459473\n",
      "\n",
      "mae 9 5.917006\n",
      "rmse 9 10.439485\n",
      "mape(>10) 9 24.715986847877502\n",
      "\n",
      "mae 10 5.6930623\n",
      "rmse 10 9.94839\n",
      "mape(>10) 10 23.994168639183044\n",
      "\n",
      "mae 11 5.9857697\n",
      "rmse 11 10.910449\n",
      "mape(>10) 11 24.98735785484314\n",
      "\n",
      "EarlyStopping counter: 1 out of 7\n",
      "mae 12 5.565188\n",
      "rmse 12 10.199126\n",
      "mape(>10) 12 23.925909399986267\n",
      "\n",
      "EarlyStopping counter: 2 out of 7\n",
      "mae 13 5.612858\n",
      "rmse 13 10.119295\n",
      "mape(>10) 13 24.066002666950226\n",
      "\n",
      "EarlyStopping counter: 3 out of 7\n",
      "mae 14 5.219991\n",
      "rmse 14 9.554157\n",
      "mape(>10) 14 22.411076724529266\n",
      "\n",
      "mae 15 5.9464784\n",
      "rmse 15 10.53308\n",
      "mape(>10) 15 25.217846035957336\n",
      "\n",
      "EarlyStopping counter: 1 out of 7\n",
      "mae 16 5.55598\n",
      "rmse 16 10.022833\n",
      "mape(>10) 16 23.837998509407043\n",
      "\n",
      "EarlyStopping counter: 2 out of 7\n",
      "mae 17 5.3941984\n",
      "rmse 17 9.643924\n",
      "mape(>10) 17 23.249639570713043\n",
      "\n",
      "EarlyStopping counter: 3 out of 7\n",
      "mae 18 5.9369006\n",
      "rmse 18 10.5762615\n",
      "mape(>10) 18 25.777381658554077\n",
      "\n",
      "EarlyStopping counter: 4 out of 7\n",
      "mae 19 5.968378\n",
      "rmse 19 10.648706\n",
      "mape(>10) 19 25.457873940467834\n",
      "\n",
      "EarlyStopping counter: 5 out of 7\n",
      "mae 20 5.916663\n",
      "rmse 20 10.788966\n",
      "mape(>10) 20 25.307980179786682\n",
      "\n",
      "EarlyStopping counter: 6 out of 7\n",
      "mae 21 5.8019695\n",
      "rmse 21 10.437538\n",
      "mape(>10) 21 24.177005887031555\n",
      "\n",
      "EarlyStopping counter: 7 out of 7\n",
      "Early stopping\n"
     ]
    }
   ],
   "source": [
    "net = TGCN(20, 20, 72, ny_6community, device).to(device)\n",
    "    \n",
    "model_ny = train(net, X_train_ny, X_val_ny, y_train_ny, y_val_ny, \"./saved/tgcn_ny.pt\", 63, ny_6community, ny_high_similar_poi, \n",
    "                  edges_in_ny, 72, 0.01, 200, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae test 5.2405906\n",
      "rmse test 9.777584\n",
      "mape(>10) test 23.488961160182953\n"
     ]
    }
   ],
   "source": [
    "test(model_ny, X_test_ny, y_test_ny, 72, edges_in_ny, ny_high_similar_poi, 63, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time cost:  1.0813148021697998\n"
     ]
    }
   ],
   "source": [
    "nb_test = X_test_sz.shape[1]\n",
    "\n",
    "model = TGCN(20, 20, nb_test, ny_6community, device).to(device)\n",
    "model.load_state_dict(torch.load(\"./saved/tgcn_ny.pt\"))\n",
    "\n",
    "t0 = time.time()\n",
    "with torch.no_grad():\n",
    "    batched_graph1 = create_batches(X_test_ny, nb_test, edges_in_ny[:,0], edges_in_ny[:,1], 63, device)\n",
    "    batched_graph2 = create_batches(X_test_ny, nb_test, ny_high_similar_poi['i'], ny_high_similar_poi['j'], 63, device)\n",
    "    logits_test = model(batched_graph1, batched_graph2) # [nb_node, bs]\n",
    "    print('time cost: ', time.time() - t0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# GCN-SZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "Collapsed": "false",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae 0 21.572289\n",
      "rmse 0 35.49498\n",
      "mape(>10) 0 64.18524980545044\n",
      "\n",
      "mae 1 19.441395\n",
      "rmse 1 32.60053\n",
      "mape(>10) 1 55.56862950325012\n",
      "\n",
      "mae 2 18.361517\n",
      "rmse 2 31.149458\n",
      "mape(>10) 2 48.70470464229584\n",
      "\n",
      "mae 3 18.175404\n",
      "rmse 3 32.003975\n",
      "mape(>10) 3 44.490283727645874\n",
      "\n",
      "EarlyStopping counter: 1 out of 7\n",
      "mae 4 15.678753\n",
      "rmse 4 26.64277\n",
      "mape(>10) 4 44.238853454589844\n",
      "\n",
      "mae 5 15.287438\n",
      "rmse 5 26.217567\n",
      "mape(>10) 5 44.76290941238403\n",
      "\n",
      "mae 6 14.913826\n",
      "rmse 6 25.131935\n",
      "mape(>10) 6 45.28956115245819\n",
      "\n",
      "mae 7 14.579987\n",
      "rmse 7 24.558638\n",
      "mape(>10) 7 45.28106153011322\n",
      "\n",
      "mae 8 14.6053505\n",
      "rmse 8 24.216417\n",
      "mape(>10) 8 46.15618586540222\n",
      "\n",
      "mae 9 14.513723\n",
      "rmse 9 23.905525\n",
      "mape(>10) 9 45.964252948760986\n",
      "\n",
      "mae 10 14.2843\n",
      "rmse 10 23.415873\n",
      "mape(>10) 10 44.94393765926361\n",
      "\n",
      "mae 11 14.084131\n",
      "rmse 11 23.25454\n",
      "mape(>10) 11 45.20532190799713\n",
      "\n",
      "mae 12 14.032031\n",
      "rmse 12 23.09624\n",
      "mape(>10) 12 44.792240858078\n",
      "\n",
      "mae 13 13.95388\n",
      "rmse 13 22.97678\n",
      "mape(>10) 13 44.734951853752136\n",
      "\n",
      "mae 14 13.979988\n",
      "rmse 14 23.076511\n",
      "mape(>10) 14 45.29068470001221\n",
      "\n",
      "EarlyStopping counter: 1 out of 7\n",
      "mae 15 13.919491\n",
      "rmse 15 22.958904\n",
      "mape(>10) 15 44.25860941410065\n",
      "\n",
      "mae 16 14.098178\n",
      "rmse 16 23.264883\n",
      "mape(>10) 16 46.7839777469635\n",
      "\n",
      "EarlyStopping counter: 1 out of 7\n",
      "mae 17 14.016313\n",
      "rmse 17 23.207457\n",
      "mape(>10) 17 46.495839953422546\n",
      "\n",
      "EarlyStopping counter: 2 out of 7\n",
      "mae 18 14.050024\n",
      "rmse 18 23.183596\n",
      "mape(>10) 18 46.03159427642822\n",
      "\n",
      "EarlyStopping counter: 3 out of 7\n",
      "mae 19 13.953453\n",
      "rmse 19 22.995022\n",
      "mape(>10) 19 44.90888714790344\n",
      "\n",
      "EarlyStopping counter: 4 out of 7\n",
      "mae 20 14.034146\n",
      "rmse 20 23.138653\n",
      "mape(>10) 20 45.627737045288086\n",
      "\n",
      "EarlyStopping counter: 5 out of 7\n",
      "mae 21 13.927946\n",
      "rmse 21 22.973486\n",
      "mape(>10) 21 44.39525902271271\n",
      "\n",
      "EarlyStopping counter: 6 out of 7\n",
      "mae 22 14.027213\n",
      "rmse 22 23.189405\n",
      "mape(>10) 22 46.375077962875366\n",
      "\n",
      "EarlyStopping counter: 7 out of 7\n",
      "Early stopping\n"
     ]
    }
   ],
   "source": [
    "gcn = SimpleGCN11(24, 20, 72, 101, device).to(device)\n",
    "gcn_sz =  train(gcn, X_train_sz, X_val_sz, y_train_sz, y_val_sz, \"./saved/gcn_sz-new.pt\", 101, sz_8community, high_similar_poi_sz, \n",
    "                  edges_in_sz, batch_size = 72, learning_rate=0.01, epochs=200, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae test 14.263112\n",
      "rmse test 23.16417\n",
      "mape(>10) test 44.70433592796326\n"
     ]
    }
   ],
   "source": [
    "test(gcn_sz, X_test_sz, y_test_sz, 72, edges_in_sz, high_similar_poi_sz, 101, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time cost:  0.8680210113525391\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "device = torch.device('cuda')\n",
    "nb_test = X_test_sz.shape[1]\n",
    "\n",
    "model = SimpleGCN11(24, 20, 72, 101, device).to(device)\n",
    "model.load_state_dict(torch.load(\"./saved/gcn_sz-new.pt\"))\n",
    "\n",
    "t0 = time.time()\n",
    "with torch.no_grad():\n",
    "    batched_graph1 = create_batches(X_test_sz, nb_test, edges_in_sz[:,0], edges_in_sz[:,1], 101, device)\n",
    "    batched_graph2 = create_batches(X_test_sz, nb_test, high_similar_poi_sz['i'], high_similar_poi_sz['j'], 101, device)\n",
    "    logits_test = model(batched_graph1, batched_graph2) # [nb_node, bs]\n",
    "    print('time cost: ', time.time() - t0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# GCN-NY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "Collapsed": "false",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae 0 14.543928\n",
      "rmse 0 32.11388\n",
      "mape(>10) 0 65.01575112342834\n",
      "\n",
      "mae 1 13.444556\n",
      "rmse 1 30.307028\n",
      "mape(>10) 1 59.51480269432068\n",
      "\n",
      "mae 2 12.633872\n",
      "rmse 2 27.948252\n",
      "mape(>10) 2 55.31506538391113\n",
      "\n",
      "mae 3 12.048494\n",
      "rmse 3 26.411545\n",
      "mape(>10) 3 55.09911775588989\n",
      "\n",
      "mae 4 11.797436\n",
      "rmse 4 25.836926\n",
      "mape(>10) 4 55.185818672180176\n",
      "\n",
      "mae 5 12.167112\n",
      "rmse 5 27.012894\n",
      "mape(>10) 5 57.618647813797\n",
      "\n",
      "EarlyStopping counter: 1 out of 7\n",
      "mae 6 11.976238\n",
      "rmse 6 26.159227\n",
      "mape(>10) 6 57.435542345047\n",
      "\n",
      "EarlyStopping counter: 2 out of 7\n",
      "mae 7 11.934835\n",
      "rmse 7 26.057175\n",
      "mape(>10) 7 57.16792941093445\n",
      "\n",
      "EarlyStopping counter: 3 out of 7\n",
      "mae 8 12.045452\n",
      "rmse 8 26.242498\n",
      "mape(>10) 8 55.48233985900879\n",
      "\n",
      "EarlyStopping counter: 4 out of 7\n",
      "mae 9 12.550909\n",
      "rmse 9 27.093061\n",
      "mape(>10) 9 56.73884153366089\n",
      "\n",
      "EarlyStopping counter: 5 out of 7\n",
      "mae 10 12.087004\n",
      "rmse 10 26.477774\n",
      "mape(>10) 10 57.126736640930176\n",
      "\n",
      "EarlyStopping counter: 6 out of 7\n",
      "mae 11 11.945834\n",
      "rmse 11 25.905634\n",
      "mape(>10) 11 55.52185773849487\n",
      "\n",
      "EarlyStopping counter: 7 out of 7\n",
      "Early stopping\n"
     ]
    }
   ],
   "source": [
    "gcn = SimpleGCN11(24, 20, 72, 63, device).to(device)\n",
    "gcn_ny =  train(gcn, X_train_ny, X_val_ny, y_train_ny, y_val_ny, \"./saved/gcn_ny-new.pt\", 63, ny_6community, ny_high_similar_poi, \n",
    "                  edges_in_ny, batch_size = 72, learning_rate=0.01, epochs=200, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae test 11.661935\n",
      "rmse test 25.417847\n",
      "mape(>10) test 56.45459294319153\n"
     ]
    }
   ],
   "source": [
    "test(gcn_ny, X_test_ny, y_test_ny, 72, edges_in_ny, ny_high_similar_poi, 63, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time cost:  0.8706495761871338\n"
     ]
    }
   ],
   "source": [
    "nb_test = X_test_sz.shape[1]\n",
    "\n",
    "model = gcn = SimpleGCN11(24, 20, 72, 63, device).to(device)\n",
    "model.load_state_dict(torch.load(\"./saved/gcn_ny-new.pt\"))\n",
    "\n",
    "t0 = time.time()\n",
    "with torch.no_grad():\n",
    "    batched_graph1 = create_batches(X_test_ny, nb_test, edges_in_ny[:,0], edges_in_ny[:,1], 63, device)\n",
    "    batched_graph2 = create_batches(X_test_ny, nb_test, ny_high_similar_poi['i'], ny_high_similar_poi['j'], 63, device)\n",
    "    logits_test = model(batched_graph1, batched_graph2) # [nb_node, bs]\n",
    "    print('time cost: ', time.time() - t0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
